# excel_agent_with_custom_workflow.py
import asyncio
from typing import TypedDict, List, Dict, Any
from openai import OpenAI
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_mcp_adapters.tools import load_mcp_tools
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from langchain_core.tools import BaseTool
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode


class AgentState(TypedDict):
    """ä»£ç†çŠ¶æ€å®šä¹‰"""
    messages: List[Any]
    iteration_count: int
    max_iterations: int


def get_first_model_name():
    """è·å–ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ¨¡å‹åç§°"""
    try:
        client = OpenAI(
            base_url="http://10.180.116.5:6390/v1",
            api_key="dummy"
        )
        models = client.models.list()
        return models.data[0].id
    except Exception as e:
        print(f"è·å–æ¨¡å‹åç§°å¤±è´¥: {e}")
        raise


class ExcelWorkflowAgent:
    """ä½¿ç”¨ LangGraph å·¥ä½œæµç¼–æ’çš„ Excel ä»£ç†"""
    
    def __init__(self, llm: ChatOpenAI, tools: List[BaseTool]):
        self.llm = llm
        self.tools = tools
        self.tool_node = ToolNode(tools)
        self.workflow = self._create_workflow()
    
    def _create_workflow(self) -> StateGraph:
        """åˆ›å»ºå·¥ä½œæµç¨‹å›¾"""
        workflow = StateGraph(AgentState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("agent", self._agent_node)
        workflow.add_node("action", self._action_node)
        workflow.add_node("finish", self._finish_node)
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("agent")
        
        # æ·»åŠ æ¡ä»¶è¾¹
        workflow.add_conditional_edges(
            "agent",
            self._should_continue,
            {
                "continue": "action",
                "finish": "finish"
            }
        )
        
        # æ·»åŠ è¾¹
        workflow.add_edge("action", "agent")
        workflow.add_edge("finish", END)
        
        return workflow.compile()
    
    def _agent_node(self, state: AgentState) -> Dict[str, Any]:
        """ä»£ç†èŠ‚ç‚¹ï¼šå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨"""
        print(f"ğŸ¤– ä»£ç†æ€è€ƒä¸­... (ç¬¬ {state['iteration_count'] + 1} æ¬¡è¿­ä»£)")
        
        # æ„å»ºç³»ç»Ÿæ¶ˆæ¯
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Excelæ•°æ®åˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. å¿…é¡»é¦–å…ˆä½¿ç”¨æä¾›çš„å·¥å…·è¯»å–Excelæ–‡ä»¶æ•°æ®
2. åŸºäºè¯»å–çš„æ•°æ®è¿›è¡Œåˆ†æ
3. æä¾›è¯¦ç»†çš„åˆ†ææŠ¥å‘Š

é‡è¦ï¼šä½ å¿…é¡»å…ˆè°ƒç”¨å·¥å…·è·å–æ•°æ®ï¼Œç„¶åå†è¿›è¡Œåˆ†æã€‚ä¸è¦åœ¨æ²¡æœ‰è¯»å–æ•°æ®çš„æƒ…å†µä¸‹ç»™å‡ºç­”æ¡ˆã€‚

å¯ç”¨å·¥å…·ï¼š
""" + "\n".join([f"- {tool.name}: {tool.description}" for tool in self.tools])
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [HumanMessage(content=system_prompt)] + state["messages"]
        
        # è°ƒç”¨LLM
        response = self.llm.bind_tools(self.tools).invoke(messages)
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        print(f"ğŸ” LLMå“åº”ç±»å‹: {type(response)}")
        print(f"ğŸ” å“åº”å†…å®¹: {response.content[:200]}...")
        if hasattr(response, 'tool_calls'):
            print(f"ğŸ” å·¥å…·è°ƒç”¨æ•°é‡: {len(response.tool_calls) if response.tool_calls else 0}")
            if response.tool_calls:
                for i, tool_call in enumerate(response.tool_calls):
                    print(f"ğŸ” å·¥å…·è°ƒç”¨ {i+1}: {tool_call}")
        
        # æ›´æ–°çŠ¶æ€
        new_state = {
            "messages": state["messages"] + [response],
            "iteration_count": state["iteration_count"] + 1
        }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨ï¼ˆä»…ç”¨äºæ—¥å¿—è¾“å‡ºï¼‰
        if hasattr(response, 'tool_calls') and response.tool_calls:
            print(f"ğŸ”§ è®¡åˆ’ä½¿ç”¨å·¥å…·: {response.tool_calls[0]['name']}")
        else:
            print("âœ… ä»£ç†ç»™å‡ºäº†å›ç­”ï¼Œå‡†å¤‡å®Œæˆ")
        
        return new_state
    
    def _action_node(self, state: AgentState) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
        last_message = state["messages"][-1]
        
        print(f"ğŸ› ï¸ æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œå…± {len(last_message.tool_calls)} ä¸ªå·¥å…·")
        
        # ä½¿ç”¨ ToolNode æ‰§è¡Œå·¥å…·è°ƒç”¨
        tool_result = self.tool_node.invoke(state)
        
        print(f"âœ… å·¥å…·æ‰§è¡Œå®Œæˆ")
        
        return tool_result
    
    def _finish_node(self, state: AgentState) -> Dict[str, Any]:
        """å®ŒæˆèŠ‚ç‚¹"""
        print("ğŸ‰ ä»»åŠ¡å®Œæˆï¼")
        
        # ä»æœ€åä¸€æ¡AIæ¶ˆæ¯ä¸­è·å–æœ€ç»ˆç­”æ¡ˆ
        final_answer = "ä»»åŠ¡å·²å®Œæˆ"
        if state["messages"]:
            last_message = state["messages"][-1]
            if hasattr(last_message, 'content') and last_message.content:
                final_answer = last_message.content
        
        return {"final_answer": final_answer}
    
    def _should_continue(self, state: AgentState) -> str:
        """å†³å®šæ˜¯å¦ç»§ç»­æ‰§è¡Œ"""
        # æ£€æŸ¥è¿­ä»£æ¬¡æ•°
        if state["iteration_count"] >= state["max_iterations"]:
            print(f"âš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° ({state['max_iterations']})")
            return "finish"
        
        # æ£€æŸ¥æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨
        if state["messages"]:
            last_message = state["messages"][-1]
            if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
                print(f"ğŸ” æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œç»§ç»­æ‰§è¡Œ")
                return "continue"
        
        # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œåˆ™å®Œæˆ
        print(f"ğŸ” æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œå‡†å¤‡å®Œæˆ")
        return "finish"
    
    async def run(self, query: str, max_iterations: int = 10) -> str:
        """è¿è¡Œå·¥ä½œæµ"""
        print("ğŸš€ å¯åŠ¨ Excel åˆ†æå·¥ä½œæµ...")
        print(f"ğŸ“‹ ç”¨æˆ·æŸ¥è¯¢: {query}\n")
        
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = {
            "messages": [HumanMessage(content=query)],
            "iteration_count": 0,
            "max_iterations": max_iterations,
        }
        
        # è¿è¡Œå·¥ä½œæµ
        final_state = await self.workflow.ainvoke(initial_state)
        
        return final_state.get("final_answer", "å·¥ä½œæµæ‰§è¡Œå®Œæˆ")


async def main():
    """ä¸»å‡½æ•°ï¼šä½¿ç”¨è‡ªå®šä¹‰å·¥ä½œæµçš„ Excel ä»£ç†"""
    
    # 1. è®¾ç½® MCP å®¢æˆ·ç«¯
    client = MultiServerMCPClient({
        "excel": {
            "transport": "streamable_http",
            "url": "http://10.180.39.254:8007/mcp",
        }
    })
    
    try:
        # 2. è·å–æ¨¡å‹åç§°å¹¶åˆå§‹åŒ– LLM
        model_name = get_first_model_name()
        llm = ChatOpenAI(
            base_url="http://10.180.116.5:6390/v1",
            api_key="dummy",
            model=model_name,
            temperature=0
        )
        
        # 3. ä½¿ç”¨ session åŠ è½½ MCP å·¥å…·
        async with client.session("excel") as session:
            tools = await load_mcp_tools(session)
            print(f"ğŸ”§ åŠ è½½äº† {len(tools)} ä¸ªå·¥å…·: {[tool.name for tool in tools]}")
            
            # 4. åˆ›å»ºè‡ªå®šä¹‰å·¥ä½œæµä»£ç†
            agent = ExcelWorkflowAgent(llm, tools)
            
            # 5. æ‰§è¡ŒæŸ¥è¯¢
            input_query = (
                "è¯»å– 20250703it.xlsx çš„ Sheet1ï¼Œå‰300è¡Œ A åˆ° D åˆ—ï¼Œ"
                "è¯·åˆ†æç”¨æˆ·ä¸»è¦å…³æ³¨å“ªäº›é—®é¢˜ï¼Œå¹¶ç»™å‡ºä¸€ä»½åˆ†ææŠ¥å‘Šã€‚"
            )
            
            # 6. è¿è¡Œå·¥ä½œæµå¹¶è·å–ç»“æœ
            result = await agent.run(input_query)
            
            print("\n" + "="*60)
            print("ğŸ“Š æœ€ç»ˆåˆ†ææŠ¥å‘Š:")
            print("="*60)
            print(result)
    
    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
    except ConnectionError as e:
        print(f"âŒ MCP å®¢æˆ·ç«¯è¿æ¥é”™è¯¯: {e}")
    except Exception as e:
        print(f"âŒ è¿è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    print("ğŸ“Š è‡ªå®šä¹‰å·¥ä½œæµ Excel Agent å¯åŠ¨ä¸­...")
    asyncio.run(main()) 