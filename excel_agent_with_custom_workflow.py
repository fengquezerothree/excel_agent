# excel_agent_with_custom_workflow.py
import asyncio
from typing import TypedDict, List, Dict, Any
from openai import OpenAI
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_mcp_adapters.tools import load_mcp_tools
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from langchain_core.tools import BaseTool
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolExecutor


class AgentState(TypedDict):
    """ä»£ç†çŠ¶æ€å®šä¹‰"""
    messages: List[Any]
    next_action: str
    iteration_count: int
    max_iterations: int
    final_answer: str


def get_first_model_name():
    """è·å–ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ¨¡å‹åç§°"""
    try:
        client = OpenAI(
            base_url="http://10.180.116.5:6390/v1",
            api_key="dummy"
        )
        models = client.models.list()
        return models.data[0].id
    except Exception as e:
        print(f"è·å–æ¨¡å‹åç§°å¤±è´¥: {e}")
        raise


class ExcelWorkflowAgent:
    """ä½¿ç”¨ LangGraph å·¥ä½œæµç¼–æ’çš„ Excel ä»£ç†"""
    
    def __init__(self, llm: ChatOpenAI, tools: List[BaseTool]):
        self.llm = llm
        self.tools = tools
        self.tool_executor = ToolExecutor(tools)
        self.workflow = self._create_workflow()
    
    def _create_workflow(self) -> StateGraph:
        """åˆ›å»ºå·¥ä½œæµç¨‹å›¾"""
        workflow = StateGraph(AgentState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("agent", self._agent_node)
        workflow.add_node("action", self._action_node)
        workflow.add_node("finish", self._finish_node)
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("agent")
        
        # æ·»åŠ æ¡ä»¶è¾¹
        workflow.add_conditional_edges(
            "agent",
            self._should_continue,
            {
                "continue": "action",
                "finish": "finish"
            }
        )
        
        # æ·»åŠ è¾¹
        workflow.add_edge("action", "agent")
        workflow.add_edge("finish", END)
        
        return workflow.compile()
    
    def _agent_node(self, state: AgentState) -> Dict[str, Any]:
        """ä»£ç†èŠ‚ç‚¹ï¼šå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨"""
        print(f"ğŸ¤– ä»£ç†æ€è€ƒä¸­... (ç¬¬ {state['iteration_count'] + 1} æ¬¡è¿­ä»£)")
        
        # æ„å»ºç³»ç»Ÿæ¶ˆæ¯
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Excelæ•°æ®åˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. ä½¿ç”¨æä¾›çš„å·¥å…·è¯»å–å’Œåˆ†æExcelæ–‡ä»¶
2. ç†è§£ç”¨æˆ·çš„éœ€æ±‚
3. æä¾›è¯¦ç»†çš„åˆ†ææŠ¥å‘Š

å¯ç”¨å·¥å…·ï¼š
""" + "\n".join([f"- {tool.name}: {tool.description}" for tool in self.tools])
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [HumanMessage(content=system_prompt)] + state["messages"]
        
        # è°ƒç”¨LLM
        response = self.llm.bind_tools(self.tools).invoke(messages)
        
        # æ›´æ–°çŠ¶æ€
        new_state = {
            "messages": state["messages"] + [response],
            "iteration_count": state["iteration_count"] + 1
        }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if response.tool_calls:
            new_state["next_action"] = "use_tool"
            print(f"ğŸ”§ è®¡åˆ’ä½¿ç”¨å·¥å…·: {response.tool_calls[0]['name']}")
        else:
            new_state["next_action"] = "finish"
            new_state["final_answer"] = response.content
            print("âœ… ä»£ç†å†³å®šå®Œæˆä»»åŠ¡")
        
        return new_state
    
    def _action_node(self, state: AgentState) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
        last_message = state["messages"][-1]
        tool_calls = last_message.tool_calls
        
        tool_messages = []
        for tool_call in tool_calls:
            print(f"ğŸ› ï¸ æ‰§è¡Œå·¥å…·: {tool_call['name']}")
            print(f"ğŸ“ å‚æ•°: {tool_call['args']}")
            
            # æ‰§è¡Œå·¥å…·
            tool_result = self.tool_executor.invoke(tool_call)
            
            # åˆ›å»ºå·¥å…·æ¶ˆæ¯
            tool_message = ToolMessage(
                content=str(tool_result),
                tool_call_id=tool_call["id"]
            )
            tool_messages.append(tool_message)
            
            print(f"âœ… å·¥å…·æ‰§è¡Œå®Œæˆ")
        
        return {"messages": state["messages"] + tool_messages}
    
    def _finish_node(self, state: AgentState) -> Dict[str, Any]:
        """å®ŒæˆèŠ‚ç‚¹"""
        print("ğŸ‰ ä»»åŠ¡å®Œæˆï¼")
        return {"final_answer": state.get("final_answer", "ä»»åŠ¡å·²å®Œæˆ")}
    
    def _should_continue(self, state: AgentState) -> str:
        """å†³å®šæ˜¯å¦ç»§ç»­æ‰§è¡Œ"""
        # æ£€æŸ¥è¿­ä»£æ¬¡æ•°
        if state["iteration_count"] >= state["max_iterations"]:
            print(f"âš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° ({state['max_iterations']})")
            return "finish"
        
        # æ£€æŸ¥ä¸‹ä¸€æ­¥è¡ŒåŠ¨
        if state.get("next_action") == "finish":
            return "finish"
        else:
            return "continue"
    
    async def run(self, query: str, max_iterations: int = 10) -> str:
        """è¿è¡Œå·¥ä½œæµ"""
        print("ğŸš€ å¯åŠ¨ Excel åˆ†æå·¥ä½œæµ...")
        print(f"ğŸ“‹ ç”¨æˆ·æŸ¥è¯¢: {query}\n")
        
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = {
            "messages": [HumanMessage(content=query)],
            "next_action": "",
            "iteration_count": 0,
            "max_iterations": max_iterations,
            "final_answer": ""
        }
        
        # è¿è¡Œå·¥ä½œæµ
        final_state = await self.workflow.ainvoke(initial_state)
        
        return final_state.get("final_answer", "å·¥ä½œæµæ‰§è¡Œå®Œæˆ")


async def main():
    """ä¸»å‡½æ•°ï¼šä½¿ç”¨è‡ªå®šä¹‰å·¥ä½œæµçš„ Excel ä»£ç†"""
    
    # 1. è®¾ç½® MCP å®¢æˆ·ç«¯
    client = MultiServerMCPClient({
        "excel": {
            "transport": "streamable_http",
            "url": "http://localhost:8007/mcp",
        }
    })
    
    try:
        # 2. è·å–æ¨¡å‹åç§°å¹¶åˆå§‹åŒ– LLM
        model_name = get_first_model_name()
        llm = ChatOpenAI(
            base_url="http://10.180.116.5:6390/v1",
            api_key="dummy",
            model=model_name,
            temperature=0
        )
        
        # 3. ä½¿ç”¨ session åŠ è½½ MCP å·¥å…·
        async with client.session("excel") as session:
            tools = await load_mcp_tools(session)
            print(f"ğŸ”§ åŠ è½½äº† {len(tools)} ä¸ªå·¥å…·: {[tool.name for tool in tools]}")
            
            # 4. åˆ›å»ºè‡ªå®šä¹‰å·¥ä½œæµä»£ç†
            agent = ExcelWorkflowAgent(llm, tools)
            
            # 5. æ‰§è¡ŒæŸ¥è¯¢
            input_query = (
                "è¯»å– 20250703it.xlsx çš„ Sheet1ï¼Œå‰300è¡Œ A åˆ° D åˆ—ï¼Œ"
                "è¯·åˆ†æç”¨æˆ·ä¸»è¦å…³æ³¨å“ªäº›é—®é¢˜ï¼Œå¹¶ç»™å‡ºä¸€ä»½åˆ†ææŠ¥å‘Šã€‚"
            )
            
            # 6. è¿è¡Œå·¥ä½œæµå¹¶è·å–ç»“æœ
            result = await agent.run(input_query)
            
            print("\n" + "="*60)
            print("ğŸ“Š æœ€ç»ˆåˆ†ææŠ¥å‘Š:")
            print("="*60)
            print(result)
    
    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
    except ConnectionError as e:
        print(f"âŒ MCP å®¢æˆ·ç«¯è¿æ¥é”™è¯¯: {e}")
    except Exception as e:
        print(f"âŒ è¿è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    print("ğŸ“Š è‡ªå®šä¹‰å·¥ä½œæµ Excel Agent å¯åŠ¨ä¸­...")
    asyncio.run(main()) 